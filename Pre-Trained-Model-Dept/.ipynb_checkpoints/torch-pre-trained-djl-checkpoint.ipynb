{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8a139-6b33-4b1f-a56c-89f61858158a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895b255c-d522-4c67-b26a-21267b6fb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sagemaker torch boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53cb81e5-5829-472d-9a8a-4c3d86fe85fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "s3_model_prefix = \"djl-sme-sklearn-regression\" \n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f35924-e508-49c8-868f-66b5e66829bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Generate dummy data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2 * X + 1 + 0.1 * np.random.randn(100, 1)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "# Define a simple Linear Regression model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # input size = 1, output size = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Save the trained model\n",
    "model_filename = \"model.pth\"\n",
    "torch.save(model.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4ee683d-5a67-4e7f-ab0f-3df5c2132ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0196571350097656]\n"
     ]
    }
   ],
   "source": [
    "# Load the model back\n",
    "loaded_model = LinearRegressionModel()\n",
    "loaded_model.load_state_dict(torch.load(model_filename))\n",
    "loaded_model.eval()\n",
    "\n",
    "\n",
    "payload = [[0.5]]\n",
    "\n",
    "# Sample inference\n",
    "payload = torch.tensor(payload).float()\n",
    "res = loaded_model(payload).detach().numpy().tolist()[0]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47952ba-5951-4a73-b98e-7069fb339187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from djl_python import Input\n",
    "from djl_python import Output\n",
    "\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # simple 1D linear regressor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class TorchRegressorService(object):\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, properties: dict):\n",
    "        \"\"\"\n",
    "        Initialize model: load from model.pth\n",
    "        \"\"\"\n",
    "        print(os.listdir())\n",
    "        if os.path.exists(\"model.pth\"):\n",
    "            self.model = LinearRegressionModel()\n",
    "            self.model.load_state_dict(torch.load(\"model.pth\", map_location=torch.device('cpu')))\n",
    "            self.model.eval()\n",
    "        else:\n",
    "            raise ValueError(\"Expecting a model.pth artifact for PyTorch Model Loading\")\n",
    "        self.initialized = True\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\"\n",
    "        Perform inference on the input data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = inputs.get_as_json()\n",
    "            print(data)\n",
    "            print(type(data))\n",
    "\n",
    "            # Convert input data to tensor\n",
    "            tensor_input = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "            # Predict\n",
    "            with torch.no_grad():\n",
    "                prediction = self.model(tensor_input)\n",
    "                prediction = prediction.numpy().tolist()[0]\n",
    "\n",
    "            # Prepare output\n",
    "            outputs = Output()\n",
    "            outputs.add_as_json(prediction)\n",
    "        except Exception as e:\n",
    "            logging.exception(\"Inference failed\")\n",
    "            outputs = Output().error(str(e))\n",
    "\n",
    "        print(outputs)\n",
    "        print(type(outputs))\n",
    "        print(\"Returning inference---------\")\n",
    "        return outputs\n",
    "\n",
    "\n",
    "_service = TorchRegressorService()\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    \"\"\"\n",
    "    Default handle function\n",
    "    \"\"\"\n",
    "    if not _service.initialized:\n",
    "        _service.initialize(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "\n",
    "    return _service.inference(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b762a175-f62a-4ad5-af65-3c9aa431c0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fa84b8d-2974-4d81-be0a-80370699449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build tar file with model data + inference code, add requirements.txt\n",
    "import subprocess\n",
    "bashCommand = \"tar -cvpzf model.tar.gz model.pth model.py serving.properties\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa593385-754c-465f-8286-4a5da2bf5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload model data to S3\n",
    "with open(\"model.tar.gz\", \"rb\") as f:\n",
    "    s3_client.upload_fileobj(f, bucket, \"{}/model.tar.gz\".format(s3_model_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e895af4a-dade-44b8-aac4-a4580c53193b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-474422712127/djl-sme-sklearn-regression/model.tar.gz'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sme_artifacts = \"s3://{}/{}/{}\".format(bucket, s3_model_prefix, \"model.tar.gz\")\n",
    "sme_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8e531b3-ebc9-4d96-89dd-d40b2806be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace this with your ECR image URI based off of your region, we are utilizing the CPU image here\n",
    "inference_image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-cpu-full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64dfd0a2-7fbd-4a0a-bd12-99d58ab4828c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: pt-djl-sme2025-04-27-20-56-20\n",
      "Created Model: arn:aws:sagemaker:us-east-1:474422712127:model/pt-djl-sme2025-04-27-20-56-20\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Model Creation\n",
    "sme_model_name = \"pt-djl-sme\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Model name: \" + sme_model_name)\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sme_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\"Image\": inference_image_uri, \"Mode\": \"SingleModel\", \"ModelDataUrl\": sme_artifacts},\n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80aae685-e322-478c-84e7-d57157c56525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:474422712127:endpoint-config/pt-djl-sme-epc2025-04-27-20-56-33\n"
     ]
    }
   ],
   "source": [
    "#Step 2: EPC Creation\n",
    "sme_epc_name = \"pt-djl-sme-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=sme_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": sme_model_name,\n",
    "            \"InstanceType\": \"ml.c5.xlarge\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445c307-b3c5-4c28-a445-8c4f7ef43456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc3dbd-2e90-4d32-b0b0-01ba9d9aba28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6495bc-724f-4e75-a22e-f901aac10e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc7159-0b1f-4674-a8c7-1e79ae5d5abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
